{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter Sentiment Analysis ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Minta tolong jangan di edit/di hapus di file original ini :\""
      ],
      "metadata": {
        "id": "A1y_4Hl6b0MN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Twitter Sentiment Analysis\n",
        "\n",
        "Aranged by StudentID-StudentName:\n",
        "\n",
        "12S18033-Cristina Sriwahyuni Hasibuan\n",
        "\n",
        "12S18038-Naomi A. Simatupang\n",
        "\n",
        "12S18049-Natasya Sitorus\n",
        "\n",
        "12S18060-Elsaday Bakara"
      ],
      "metadata": {
        "id": "K3-RVRXZ5fve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Start a Session"
      ],
      "metadata": {
        "id": "meQqOM5UaOsR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xi-NhSE8w5wh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db6e9d47-75cb-4c19-dde5-4f3ce89e3342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.3)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Memulai Spark Session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "  .master(\"local[2]\") \\\n",
        "  .appName(\"Proyek_Sentiment Analysis\") \\\n",
        "  .getOrCreate()\n"
      ],
      "metadata": {
        "id": "OhsszDzzG0Qp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "chHJZiX9anqo",
        "outputId": "61cac364-c891-4dbd-9241-d726592e7191"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f7ebfacc090>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e8e48a61ea8a:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[2]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Proyek_Sentiment Analysis</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # melakukan load dataset menggunakan library pandas (dikarenakan Spark load data tidak sesuai)\n",
        "# df = df\n",
        "# # melakukan load dataset kedalam Spark dan menampilkannya\n",
        "# reviews = spark.createDataFrame(df)\n",
        "# reviews.show(10)\n",
        "# # melakukan Konversi Data ke format Parquet\n",
        "# reviews.write.format(\"parquet\").mode(\"overwrite\").save(\"D:/semester8/PDB/Proyek/Data_Parquet\")\n"
      ],
      "metadata": {
        "id": "LgH2NrEyHEMR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Requirements installation if not exist yet"
      ],
      "metadata": {
        "id": "46dk25eHmhJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqhebfZ9Ak1r",
        "outputId": "9cbf8398-fd55-4a42-cd7a-ad784fe02a44"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tweepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEfxc0otWzKi",
        "outputId": "a886126a-e6ac-457e-b1f4-3bb822bfd25c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.27.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.2.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2022.5.18.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.0.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install preprocessor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASZHkUm5GCMY",
        "outputId": "93357ce3-e2c2-4688-c7be-68bf23ba03cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: preprocessor in /usr/local/lib/python3.7/dist-packages (1.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRDTnC1FAL9I",
        "outputId": "a8fc046a-0a5b-4537-abdd-14298ca11d17"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: utils in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Sastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tc8OLiuMScB",
        "outputId": "9f24fe84-2786-441c-a7f7-e9628c429e85"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49Jo22W_MacV",
        "outputId": "1506a7ad-c25a-40c5-d014-791f9d707285"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Lib"
      ],
      "metadata": {
        "id": "ZxpwCA3P-npR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import json\n",
        "import csv\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import Stream\n",
        "from collections import Counter\n",
        "from plotly import graph_objs as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.ml.feature import Tokenizer, StringIndexer, Word2Vec, StopWordsRemover, HashingTF\n",
        "from pyspark.ml import Pipeline, Transformer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics"
      ],
      "metadata": {
        "id": "cFjFe3t1Gl3Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from datetime import timedelta, datetime\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import matplotlib.pyplot as plt \n",
        "from tweepy import OAuthHandler\n",
        "from textblob import TextBlob\n",
        "import preprocessor as p\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tweepy\n",
        "import csv\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcS_1xmPF-Mw",
        "outputId": "b24d2024-98d7-4d19-b303-61572399638a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import some libraries\n",
        "\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "import numpy as np\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style = 'whitegrid')\n",
        "\n",
        "import datetime as dt\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Dropout, LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "mmvN0TIGMEVI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Configuration"
      ],
      "metadata": {
        "id": "NCqJdwHUmVRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# APIKey = \"QnupptSEsqShuukhaPGsk0Svf\"\n",
        "# APISecretKey = \"HuD4bnPtEZcE1IVFDcluzuYcngbSMMYxKyfYA8MTXPUYZvn4N0\"\n",
        "# AccessToken = \"1390698546353999878-KExzyOWL2qm1zfmxZdrYmcnkaVbjue\"\n",
        "# AccessTokenSecret = \"dkEkoVa4QwW3Z8Rzvau6r37C7DhnUPU2zu91P6GZmm7Ec\"\n",
        "# BearerToken =\"AAAAAAAAAAAAAAAAAAAAALP5cAEAAAAACkdJeE7i23YH3L4qeYWpvoeqZAA%3DoOefkiPYcftGrIzdm9YgPi7hnYrI6ymuojs6031Dd5K5U7CWul\""
      ],
      "metadata": {
        "id": "6ZabgOxHhJSt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TrackWords = ['covid']"
      ],
      "metadata": {
        "id": "4zs69ewilZFX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# today = datetime.today().strftime(\"%Y-%m-%d\")\n",
        "# last_week = datetime.today() - timedelta(7)\n",
        "# last_week = last_week.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# date_since = last_week\n",
        "# date_until = today"
      ],
      "metadata": {
        "id": "ovFWzMnqF0VQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set Up"
      ],
      "metadata": {
        "id": "bccZ9r4N37V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def connectOAuth():\n",
        "#     auth = OAuthHandler(APIKey, APISecretKey)\n",
        "#     auth.set_access_token(AccessToken, AccessTokenSecret)\n",
        "\n",
        "#     api = tweepy.API(auth, wait_on_rate_limit=True)\n",
        "#     return api"
      ],
      "metadata": {
        "id": "ZS6_knNj3g8U"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# API = connectOAuth()"
      ],
      "metadata": {
        "id": "Ffd2bEep5DwZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Scrapping"
      ],
      "metadata": {
        "id": "63gYJ5Zc0tfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def scraptweets(search_words, date_since, date_until):\n",
        "\n",
        "#     db_tweets = pd.DataFrame(columns=['username', 'tweetcreatedts', 'text'])\n",
        "\n",
        "#     tweets = tweepy.Cursor(\n",
        "#                     API.search,\n",
        "#                     q=search_words,\n",
        "#                     lang=\"id\", \n",
        "#                     since=date_since,\n",
        "#                     until=date_until,\n",
        "#                     tweet_mode='extended').items(1000)\n",
        "\n",
        "#     tweet_list = [tweet for tweet in tweets]\n",
        "\n",
        "#     for tweet in tweet_list:\n",
        "#         username = tweet.user.screen_name\n",
        "#         tweetcreatedts = tweet.created_at\n",
        "\n",
        "#         try:\n",
        "#             text = tweet.retweeted_status.full_text\n",
        "#         except AttributeError:\n",
        "#             text = tweet.full_text\n",
        "\n",
        "#         ith_tweet = [username, tweetcreatedts, text]\n",
        "\n",
        "#         db_tweets.loc[len(db_tweets)] = ith_tweet\n",
        "    \n",
        "#     print('Proses Scrapping Selesai Dengan Jumlah Data', len(db_tweets))\n",
        "#     filename = 'reviews.csv'\n",
        "#     db_tweets.to_csv(filename, index=False)"
      ],
      "metadata": {
        "id": "lbMDz8MqFtzQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scraptweets(TrackWords, date_since, date_until)"
      ],
      "metadata": {
        "id": "ellQLwxrFt2a"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Data"
      ],
      "metadata": {
        "id": "9QXHyFms80D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/reviews.csv', delimiter=\",\")"
      ],
      "metadata": {
        "id": "q1NgTjzj-HO8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH7UJLcOIV13",
        "outputId": "4f53b3df-45b4-4839-ef7c-f937e965d8b2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "username          0\n",
              "tweetcreatedts    0\n",
              "text              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "_wlJkRM1VDAi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "6fb1a4b9-a01f-4b5f-f496-5e42085b8cdd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        username       tweetcreatedts  \\\n",
              "0  SallehZamzuri  2022-05-24 23:59:42   \n",
              "1    amirsyahoke  2022-05-24 23:59:39   \n",
              "2       mighaa__  2022-05-24 23:59:30   \n",
              "3   fikrierazeen  2022-05-24 23:59:25   \n",
              "4  hakimrusman96  2022-05-24 23:59:15   \n",
              "5  eko_n9udiarto  2022-05-24 23:59:12   \n",
              "6     lapastolis  2022-05-24 23:59:07   \n",
              "7       nshminnn  2022-05-24 23:58:52   \n",
              "8       saguna22  2022-05-24 23:58:49   \n",
              "9        nahkiwi  2022-05-24 23:58:19   \n",
              "\n",
              "                                                text  \n",
              "0  Pastikan anda hadkan masa berada di kawasan se...  \n",
              "1  Jumlah penumpang kendaraan umum mudik Lebaran ...  \n",
              "2  Inilah contoh, bangang pun boleh dapat PhD ya ...  \n",
              "3  Inilah contoh, bangang pun boleh dapat PhD ya ...  \n",
              "4  Inilah contoh, bangang pun boleh dapat PhD ya ...  \n",
              "5  Arab Saudi larang warganya ke Indonesia karena...  \n",
              "6  untuk bersama-sama mengobarkan semangat bangki...  \n",
              "7  Inilah contoh, bangang pun boleh dapat PhD ya ...  \n",
              "8  Arab Saudi larang warganya ke Indonesia karena...  \n",
              "9  Inilah contoh, bangang pun boleh dapat PhD ya ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e1c5568-3c48-474a-8819-de17fd42b526\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>tweetcreatedts</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SallehZamzuri</td>\n",
              "      <td>2022-05-24 23:59:42</td>\n",
              "      <td>Pastikan anda hadkan masa berada di kawasan se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>amirsyahoke</td>\n",
              "      <td>2022-05-24 23:59:39</td>\n",
              "      <td>Jumlah penumpang kendaraan umum mudik Lebaran ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mighaa__</td>\n",
              "      <td>2022-05-24 23:59:30</td>\n",
              "      <td>Inilah contoh, bangang pun boleh dapat PhD ya ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fikrierazeen</td>\n",
              "      <td>2022-05-24 23:59:25</td>\n",
              "      <td>Inilah contoh, bangang pun boleh dapat PhD ya ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hakimrusman96</td>\n",
              "      <td>2022-05-24 23:59:15</td>\n",
              "      <td>Inilah contoh, bangang pun boleh dapat PhD ya ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>eko_n9udiarto</td>\n",
              "      <td>2022-05-24 23:59:12</td>\n",
              "      <td>Arab Saudi larang warganya ke Indonesia karena...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lapastolis</td>\n",
              "      <td>2022-05-24 23:59:07</td>\n",
              "      <td>untuk bersama-sama mengobarkan semangat bangki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>nshminnn</td>\n",
              "      <td>2022-05-24 23:58:52</td>\n",
              "      <td>Inilah contoh, bangang pun boleh dapat PhD ya ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>saguna22</td>\n",
              "      <td>2022-05-24 23:58:49</td>\n",
              "      <td>Arab Saudi larang warganya ke Indonesia karena...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>nahkiwi</td>\n",
              "      <td>2022-05-24 23:58:19</td>\n",
              "      <td>Inilah contoh, bangang pun boleh dapat PhD ya ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e1c5568-3c48-474a-8819-de17fd42b526')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e1c5568-3c48-474a-8819-de17fd42b526 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e1c5568-3c48-474a-8819-de17fd42b526');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'].head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndqm8QbrVGZK",
        "outputId": "827ecf4e-bb6f-4894-b933-7049717aa88f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Pastikan anda hadkan masa berada di kawasan se...\n",
              "1    Jumlah penumpang kendaraan umum mudik Lebaran ...\n",
              "2    Inilah contoh, bangang pun boleh dapat PhD ya ...\n",
              "3    Inilah contoh, bangang pun boleh dapat PhD ya ...\n",
              "4    Inilah contoh, bangang pun boleh dapat PhD ya ...\n",
              "5    Arab Saudi larang warganya ke Indonesia karena...\n",
              "6    untuk bersama-sama mengobarkan semangat bangki...\n",
              "7    Inilah contoh, bangang pun boleh dapat PhD ya ...\n",
              "8    Arab Saudi larang warganya ke Indonesia karena...\n",
              "9    Inilah contoh, bangang pun boleh dapat PhD ya ...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Tweets"
      ],
      "metadata": {
        "id": "WOTmiTb4-gzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #stopwords\n",
        "# def remove_stopwords(tweets):\n",
        "#   \"\"\"\n",
        "#   Remove Stopwords using nltk\n",
        "#   \"\"\"\n",
        "\n",
        "#   stopwords = pd.read_csv('/content/stopwords')\n",
        "#   tweets_without_stopwords = []\n",
        "\n",
        "#   for sentence in tweets:\n",
        "\n",
        "#     temp = [word for word in sentence if not word in stopwords]\n",
        "#     tweets_without_stopwords.append(temp) \n",
        "\n",
        "#   return tweets_without_stopwords\n",
        "\n",
        "# def clean_tweet(tweet):\n",
        "#         '''\n",
        "#         Utility function to clean tweet text by removing links, special characters\n",
        "#         using simple regex statements.\n",
        "#         '''\n",
        "#         res = []\n",
        "#         for t in tweet:\n",
        "#             res.append(' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) |(\\w+:\\/\\/\\S+)\", \" \", t).split()))\n",
        "#         return res\n",
        "        \n",
        "#         for t in tweet:\n",
        "#           res.append(' '.join(re.sub(\"(#[A-Za-z0-9]+\", \" \", t).split()))\n",
        "#         return res\n",
        "\n",
        "#         for t in tweet:\n",
        "#           res.append(' '.join(re.sub(\"(RT[\\s]\", \" \", t).split()))\n",
        "#         return res\n",
        "\n",
        "#         for t in tweet:\n",
        "#           res.append(' '.join(re.sub(\"http\\S+\", \" \", t).split()))\n",
        "#         return res\n",
        "\n",
        "#         for t in tweet:\n",
        "#           res.append(' '.join(re.sub(\"[0-9]+\", \" \", t).split()))\n",
        "#         return res\n",
        "\n",
        "#         for t in tweet:\n",
        "#           res.append(' '.join(re.replace('\\n', ' ').split()))\n",
        "#         return res\n",
        "\n",
        "#         for t in tweet:\n",
        "#           res.append(' '.join(text.translate(str.maketrans('', '', string.punctuation))))\n",
        "#         return res\n",
        "\n",
        "# # Some functions for preprocessing text\n",
        "\n",
        "def cleaningText(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove mentions\n",
        "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # remove hashtag\n",
        "    text = re.sub(r'RT[\\s]', '', text) # remove RT\n",
        "    text = re.sub(r\"http\\S+\", '', text) # remove link\n",
        "    text = re.sub(r'[0-9]+', '', text) # remove numbers\n",
        "\n",
        "    text = text.replace('\\n', ' ') # replace new line into space\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n",
        "    text = text.strip(' ') # remove characters space from both left and right text\n",
        "    return text\n",
        "\n",
        "def casefoldingText(text): # Converting all the characters in a text into lower case\n",
        "    text = text.lower() \n",
        "    return text\n",
        "\n",
        "def tokenizingText(text): # Tokenizing or splitting a string, text into a list of tokens\n",
        "    text = word_tokenize(text) \n",
        "    return text\n",
        "\n",
        "def filteringText(text): # Remove stopwors in a text\n",
        "    listStopwords = set(pd.read_csv('/content/stopwords'))\n",
        "    filtered = []\n",
        "    for txt in text:\n",
        "        if txt not in listStopwords:\n",
        "            filtered.append(txt)\n",
        "    text = filtered \n",
        "    return text\n",
        "\n",
        "def toSentence(list_words): # Convert list of words into sentence\n",
        "    sentence = ' '.join(word for word in list_words)\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "jfaIZaiBD_Fd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing tweets data\n",
        "\n",
        "df['text_clean'] = df['text'].apply(cleaningText)\n",
        "df['text_clean'] = df['text_clean'].apply(casefoldingText)\n",
        "df.drop(['text'], axis = 1, inplace = True)\n",
        "\n",
        "df['text_preprocessed'] = df['text_clean'].apply(tokenizingText)\n",
        "df['text_preprocessed'] = df['text_preprocessed'].apply(filteringText)\n",
        "\n",
        "# drop duplicates/spams tweets\n",
        "df.drop_duplicates(subset = 'text_clean', inplace = True)"
      ],
      "metadata": {
        "id": "tmh1lQDhKHF8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_preprocessed'].head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUDcUAWRNcUY",
        "outputId": "ddcf693f-c60f-4efc-d14a-e5b6a98bc526"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     [pastikan, anda, hadkan, masa, berada, di, kaw...\n",
              "1     [jumlah, penumpang, kendaraan, umum, mudik, le...\n",
              "2     [inilah, contoh, bangang, pun, boleh, dapat, p...\n",
              "5     [arab, saudi, larang, warganya, ke, indonesia,...\n",
              "6     [untuk, bersamasama, mengobarkan, semangat, ba...\n",
              "10    [mei, petaling, jaya, menteri, perusahaan, per...\n",
              "11    [ni, lah, dia, yg, dikatakan, menumpang, padah...\n",
              "16                 [haduh, ga, dulu, deh, takut, covid]\n",
              "17    [mumet, otak, ku, luhut, juga, mengemban, seju...\n",
              "18    [innalillahi, wainna, ilaihi, rojiun, telah, b...\n",
              "Name: text_preprocessed, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Selection"
      ],
      "metadata": {
        "id": "VeSi-5bLfENp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6lr1U9y5fDVa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}