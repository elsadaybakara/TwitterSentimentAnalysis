{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter Sentiment Analysis ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Twitter Sentiment Analysis\n",
        "\n",
        "Aranged by StudentID-StudentName:\n",
        "\n",
        "12S18033-Cristina Sriwahyuni Hasibuan\n",
        "\n",
        "12S18038-Naomi A. Simatupang\n",
        "\n",
        "12S18049-Natasya Sitorus\n",
        "\n",
        "12S18060-Elsaday Bakara"
      ],
      "metadata": {
        "id": "K3-RVRXZ5fve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Requirements installation if not exist yet"
      ],
      "metadata": {
        "id": "46dk25eHmhJ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xi-NhSE8w5wh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf5eeee5-faf2-4b7b-f0f9-c469d95c65df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 25 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 51.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=882453649da0eb36e6ac4d3b4690fc074f8ce988a45cb2875ad9f987563f81ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqhebfZ9Ak1r",
        "outputId": "63277a84-f208-48bf-8675-35985507537f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tweepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEfxc0otWzKi",
        "outputId": "45586414-d7e7-4510-e3f1-7cc4e63b9b11"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install preprocessor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASZHkUm5GCMY",
        "outputId": "fa065f90-badc-4516-f40e-3622f172ed9e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting preprocessor\n",
            "  Downloading preprocessor-1.1.3.tar.gz (4.2 kB)\n",
            "Building wheels for collected packages: preprocessor\n",
            "  Building wheel for preprocessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for preprocessor: filename=preprocessor-1.1.3-py3-none-any.whl size=4477 sha256=bc4afb2eaa89ec136fd9d18ea9c59da7017a03bff371c1806f1e0464b02541f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/b7/36/aa37256db62b4bfd35a6f1b5536e9ba843f257b79dcbf3d5f1\n",
            "Successfully built preprocessor\n",
            "Installing collected packages: preprocessor\n",
            "Successfully installed preprocessor-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRDTnC1FAL9I",
        "outputId": "9e9e21d7-91a5-48c4-a329-fab08da132a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Sastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tc8OLiuMScB",
        "outputId": "91f14eac-c741-4970-b5b2-af38d173d5e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 6.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49Jo22W_MacV",
        "outputId": "5c59b266-72e8-4733-859d-d150e12b3ae2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwk6L4VxHaGL",
        "outputId": "ffc1203a-2a4c-4049-9d9b-588dff052f6c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Lib"
      ],
      "metadata": {
        "id": "ZxpwCA3P-npR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.ml.classification import LogisticRegression, LinearSVC, NaiveBayes\n",
        "import json\n",
        "import csv\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import Stream\n",
        "from collections import Counter\n",
        "from plotly import graph_objs as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.ml.feature import Tokenizer, StringIndexer, Word2Vec, StopWordsRemover, HashingTF\n",
        "from pyspark.ml import Pipeline, Transformer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics"
      ],
      "metadata": {
        "id": "cFjFe3t1Gl3Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from datetime import timedelta, datetime\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import matplotlib.pyplot as plt \n",
        "from tweepy import OAuthHandler\n",
        "from textblob import TextBlob\n",
        "import preprocessor as p\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tweepy\n",
        "import csv\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcS_1xmPF-Mw",
        "outputId": "83b069ab-cbaf-44d1-8a55-dfa9a112bdbe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import some libraries\n",
        "\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None\n",
        "import numpy as np\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style = 'whitegrid')\n",
        "\n",
        "import datetime as dt\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Dropout, LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "mmvN0TIGMEVI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "import pyspark as ps\n",
        "import warnings\n",
        "from pyspark.sql import SQLContext"
      ],
      "metadata": {
        "id": "g1Xoxl25HWeO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Start a Session"
      ],
      "metadata": {
        "id": "meQqOM5UaOsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Memulai Spark Session\n",
        "try:\n",
        "    from pyspark.sql import SparkSession\n",
        "    sc = ps.SparkContext('local[2]')\n",
        "    sqlContext = SQLContext(sc)\n",
        "    spark = SparkSession.builder \\\n",
        "      .master(\"local[2]\") \\\n",
        "      .appName(\"Proyek_Sentiment Analysis\") \\\n",
        "      .getOrCreate()\n",
        "except ValueError:\n",
        "    warnings.warn(\"SparkContext already exists in this scope\")"
      ],
      "metadata": {
        "id": "OhsszDzzG0Qp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "061f41fd-a629-4b06-acd5-76c8c58ad22d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:79: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "0dsmNXoEcPH9",
        "outputId": "965b1b9c-ccbc-4fc6-b4c2-e5aa10e87e8f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ff705cd2d50>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://d1f45aa203cd:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[2]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Configuration"
      ],
      "metadata": {
        "id": "NCqJdwHUmVRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "APIKey = \"QnupptSEsqShuukhaPGsk0Svf\"\n",
        "APISecretKey = \"HuD4bnPtEZcE1IVFDcluzuYcngbSMMYxKyfYA8MTXPUYZvn4N0\"\n",
        "AccessToken = \"1390698546353999878-KExzyOWL2qm1zfmxZdrYmcnkaVbjue\"\n",
        "AccessTokenSecret = \"dkEkoVa4QwW3Z8Rzvau6r37C7DhnUPU2zu91P6GZmm7Ec\"\n",
        "BearerToken =\"AAAAAAAAAAAAAAAAAAAAALP5cAEAAAAACkdJeE7i23YH3L4qeYWpvoeqZAA%3DoOefkiPYcftGrIzdm9YgPi7hnYrI6ymuojs6031Dd5K5U7CWul\""
      ],
      "metadata": {
        "id": "6ZabgOxHhJSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrackWords = ['covid']"
      ],
      "metadata": {
        "id": "4zs69ewilZFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
        "last_week = datetime.today() - timedelta(7)\n",
        "last_week = last_week.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "date_since = last_week\n",
        "date_until = today"
      ],
      "metadata": {
        "id": "ovFWzMnqF0VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set Up"
      ],
      "metadata": {
        "id": "bccZ9r4N37V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def connectOAuth():\n",
        "    auth = OAuthHandler(APIKey, APISecretKey)\n",
        "    auth.set_access_token(AccessToken, AccessTokenSecret)\n",
        "\n",
        "    api = tweepy.API(auth, wait_on_rate_limit=True)\n",
        "    return api"
      ],
      "metadata": {
        "id": "ZS6_knNj3g8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API = connectOAuth()"
      ],
      "metadata": {
        "id": "Ffd2bEep5DwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Scrapping"
      ],
      "metadata": {
        "id": "63gYJ5Zc0tfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scraptweets(search_words, date_since, date_until):\n",
        "\n",
        "    db_tweets = pd.DataFrame(columns=['username', 'tweetcreatedts', 'text'])\n",
        "\n",
        "    tweets = tweepy.Cursor(\n",
        "                    API.search,\n",
        "                    q=search_words,\n",
        "                    lang=\"id\", \n",
        "                    since=date_since,\n",
        "                    until=date_until,\n",
        "                    tweet_mode='extended').items(5000)\n",
        "\n",
        "    tweet_list = [tweet for tweet in tweets]\n",
        "\n",
        "    for tweet in tweet_list:\n",
        "        username = tweet.user.screen_name\n",
        "        tweetcreatedts = tweet.created_at\n",
        "\n",
        "        try:\n",
        "            text = tweet.retweeted_status.full_text\n",
        "        except AttributeError:\n",
        "            text = tweet.full_text\n",
        "\n",
        "        ith_tweet = [username, tweetcreatedts, text]\n",
        "\n",
        "        db_tweets.loc[len(db_tweets)] = ith_tweet\n",
        "    \n",
        "    print('Proses Scrapping Selesai Dengan Jumlah Data', len(db_tweets))\n",
        "    filename = 'reviews.csv'\n",
        "    db_tweets.to_csv(filename, index=False)"
      ],
      "metadata": {
        "id": "lbMDz8MqFtzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scraptweets(TrackWords, date_since, date_until)"
      ],
      "metadata": {
        "id": "ellQLwxrFt2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "828ddffb-db2b-43c4-ebeb-176f31e7fe7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proses Scrapping Selesai Dengan Jumlah Data 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Raw Data Twitter"
      ],
      "metadata": {
        "id": "9QXHyFms80D8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/reviews.csv', delimiter=\",\")"
      ],
      "metadata": {
        "id": "q1NgTjzj-HO8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qC3nDvaHNcQ",
        "outputId": "6d37d63b-8870-47d4-ccd1-630e551993aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "pnJo-hxvuRKU",
        "outputId": "43bedc3e-3b89-4692-a6c8-03355d6730f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          username       tweetcreatedts  \\\n",
              "count         2500                 2500   \n",
              "unique        1925                 2351   \n",
              "top     kebab_bksi  2022-05-26 12:00:03   \n",
              "freq            23                   14   \n",
              "\n",
              "                                                     text  \n",
              "count                                                2500  \n",
              "unique                                               1319  \n",
              "top     apa rationalnya traffic teruk eh? kenapa boleh...  \n",
              "freq                                                  354  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29745aa6-bf5b-4e4e-9c07-1b30c33a6268\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>tweetcreatedts</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2500</td>\n",
              "      <td>2500</td>\n",
              "      <td>2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>1925</td>\n",
              "      <td>2351</td>\n",
              "      <td>1319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>kebab_bksi</td>\n",
              "      <td>2022-05-26 12:00:03</td>\n",
              "      <td>apa rationalnya traffic teruk eh? kenapa boleh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>23</td>\n",
              "      <td>14</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29745aa6-bf5b-4e4e-9c07-1b30c33a6268')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29745aa6-bf5b-4e4e-9c07-1b30c33a6268 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29745aa6-bf5b-4e4e-9c07-1b30c33a6268');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "_wlJkRM1VDAi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "080b14b1-f93c-4d1b-d98d-4ca3155b9877"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         username       tweetcreatedts  \\\n",
              "0     syahpewaris  2022-05-26 23:59:33   \n",
              "1    RiyaniEmilia  2022-05-26 23:59:31   \n",
              "2       JaPenWPKL  2022-05-26 23:59:10   \n",
              "3          DokFun  2022-05-26 23:58:48   \n",
              "4  musketeers0852  2022-05-26 23:58:39   \n",
              "5   HumasBaturiti  2022-05-26 23:58:28   \n",
              "6     Rahmanamroh  2022-05-26 23:58:15   \n",
              "7      unnnsnssnn  2022-05-26 23:58:04   \n",
              "8   HumasBaturiti  2022-05-26 23:57:48   \n",
              "9        JeonMyeo  2022-05-26 23:57:40   \n",
              "\n",
              "                                                text  \n",
              "0  Berikut merupakan kelonggaran SOP COVID-19 yan...  \n",
              "1  @Kemenkumham_RI @kumhamsumsel Di masa endemi C...  \n",
              "2  Fokus Penyampaian Maklumat :\\n📌 TRIIS - Penila...  \n",
              "3  Penanganan pandemi yg dijadikan bancakan adala...  \n",
              "4  @iamzahidkhann @AsadSal @ShahzadGill202 Wo tou...  \n",
              "5  Tetap disiplin Protokol Kesehatan, walaupun Co...  \n",
              "6  @Kemenkumham_RI @kumhamsumsel Di masa endemi C...  \n",
              "7  apa rationalnya traffic teruk eh? kenapa boleh...  \n",
              "8  Ayo vaksinasi Booster, vaksinasi membangun imm...  \n",
              "9  Gp Ansor punya Andil dlm pemulihan Indonesia p...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-201415a0-afe3-4a7f-a008-36e43c75634a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>tweetcreatedts</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>syahpewaris</td>\n",
              "      <td>2022-05-26 23:59:33</td>\n",
              "      <td>Berikut merupakan kelonggaran SOP COVID-19 yan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RiyaniEmilia</td>\n",
              "      <td>2022-05-26 23:59:31</td>\n",
              "      <td>@Kemenkumham_RI @kumhamsumsel Di masa endemi C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>JaPenWPKL</td>\n",
              "      <td>2022-05-26 23:59:10</td>\n",
              "      <td>Fokus Penyampaian Maklumat :\\n📌 TRIIS - Penila...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DokFun</td>\n",
              "      <td>2022-05-26 23:58:48</td>\n",
              "      <td>Penanganan pandemi yg dijadikan bancakan adala...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>musketeers0852</td>\n",
              "      <td>2022-05-26 23:58:39</td>\n",
              "      <td>@iamzahidkhann @AsadSal @ShahzadGill202 Wo tou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>HumasBaturiti</td>\n",
              "      <td>2022-05-26 23:58:28</td>\n",
              "      <td>Tetap disiplin Protokol Kesehatan, walaupun Co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Rahmanamroh</td>\n",
              "      <td>2022-05-26 23:58:15</td>\n",
              "      <td>@Kemenkumham_RI @kumhamsumsel Di masa endemi C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>unnnsnssnn</td>\n",
              "      <td>2022-05-26 23:58:04</td>\n",
              "      <td>apa rationalnya traffic teruk eh? kenapa boleh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HumasBaturiti</td>\n",
              "      <td>2022-05-26 23:57:48</td>\n",
              "      <td>Ayo vaksinasi Booster, vaksinasi membangun imm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>JeonMyeo</td>\n",
              "      <td>2022-05-26 23:57:40</td>\n",
              "      <td>Gp Ansor punya Andil dlm pemulihan Indonesia p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-201415a0-afe3-4a7f-a008-36e43c75634a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-201415a0-afe3-4a7f-a008-36e43c75634a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-201415a0-afe3-4a7f-a008-36e43c75634a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH7UJLcOIV13",
        "outputId": "d429833f-8581-480d-b25d-d4f630514807"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "username          0\n",
              "tweetcreatedts    0\n",
              "text              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Tweets"
      ],
      "metadata": {
        "id": "WOTmiTb4-gzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'].head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndqm8QbrVGZK",
        "outputId": "37586a73-27d1-4c0b-be54-4f485ae0853b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Berikut merupakan kelonggaran SOP COVID-19 yan...\n",
              "1    @Kemenkumham_RI @kumhamsumsel Di masa endemi C...\n",
              "2    Fokus Penyampaian Maklumat :\\n📌 TRIIS - Penila...\n",
              "3    Penanganan pandemi yg dijadikan bancakan adala...\n",
              "4    @iamzahidkhann @AsadSal @ShahzadGill202 Wo tou...\n",
              "5    Tetap disiplin Protokol Kesehatan, walaupun Co...\n",
              "6    @Kemenkumham_RI @kumhamsumsel Di masa endemi C...\n",
              "7    apa rationalnya traffic teruk eh? kenapa boleh...\n",
              "8    Ayo vaksinasi Booster, vaksinasi membangun imm...\n",
              "9    Gp Ansor punya Andil dlm pemulihan Indonesia p...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaningText(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove mentions\n",
        "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # remove hashtag\n",
        "    text = re.sub(r'RT[\\s]', '', text) # remove RT\n",
        "    text = re.sub(r\"http\\S+\", '', text) # remove link\n",
        "    text = re.sub(r'[0-9]+', '', text) # remove numbers\n",
        "\n",
        "    text = text.replace('\\n', ' ') # replace new line into space\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove all punctuations\n",
        "    text = text.strip(' ') # remove characters space from both left and right text\n",
        "    return text\n",
        "\n",
        "def casefoldingText(text): # Converting all the characters in a text into lower case\n",
        "    text = text.lower() \n",
        "    return text\n",
        "\n",
        "def tokenizingText(text): # Tokenizing or splitting a string, text into a list of tokens\n",
        "    text = word_tokenize(text) \n",
        "    return text\n",
        "\n",
        "def filteringText(text): # Remove stopwors in a text\n",
        "    listStopwords = set(pd.read_csv('/content/stopwords-id.txt'))\n",
        "    filtered = []\n",
        "    for txt in text:\n",
        "        if txt not in listStopwords:\n",
        "            filtered.append(txt)\n",
        "    text = filtered \n",
        "    return text\n",
        "\n",
        "def toSentence(list_words): # Convert list of words into sentence\n",
        "    sentence = ' '.join(word for word in list_words)\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "jfaIZaiBD_Fd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing tweets data\n",
        "\n",
        "df['text_clean'] = df['text'].apply(cleaningText)\n",
        "df['text_clean'] = df['text_clean'].apply(casefoldingText)\n",
        "df.drop(['text'], axis = 1, inplace = True)\n",
        "\n",
        "df['text_preprocessed'] = df['text_clean'].apply(tokenizingText)\n",
        "df['text_preprocessed'] = df['text_preprocessed'].apply(filteringText)\n",
        "df['tweets'] = df['text_preprocessed'].apply(toSentence)\n",
        "\n",
        "# drop duplicates/spams tweets\n",
        "df.drop_duplicates(subset = 'tweets', inplace = True)\n",
        "\n",
        "df.drop(['text_clean', 'text_preprocessed'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "tmh1lQDhKHF8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FPp6DsXum87",
        "outputId": "000aa413-85db-49dc-9987-64e01460d086"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "username          1101\n",
              "tweetcreatedts    1101\n",
              "tweets            1101\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Labeling Data"
      ],
      "metadata": {
        "id": "wCp2O2hCkYRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "def sentiment_calc(tweets):\n",
        "    p = TextBlob(tweets).sentiment.polarity\n",
        "    if p<0 :\n",
        "        return(\"negatif\")\n",
        "    elif p>0 :\n",
        "        return(\"positif\")\n",
        "    else:\n",
        "        return(\"netral\")\n",
        "\n",
        "df['sentiment'] = df['tweets'].apply(sentiment_calc)"
      ],
      "metadata": {
        "id": "DBsht6MNKfSy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"sentiment\"].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XjELIzwPcTQ",
        "outputId": "12e0f42d-fc7f-4547-d3a3-89fddea9a005"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count       1101\n",
              "unique         3\n",
              "top       netral\n",
              "freq         963\n",
              "Name: sentiment, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'preprocessed_tweets.csv'\n",
        "df.to_csv(filename, index=False)"
      ],
      "metadata": {
        "id": "SENXkt6tlLTt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataFrame Pyspark SQL"
      ],
      "metadata": {
        "id": "L6DuQedboEhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/content/preprocessed_tweets.csv')\n",
        "type(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKTgQB8GoP3h",
        "outputId": "78ef402a-d5c5-4afb-d1c8-c79555d5fc3c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc3iK4pCqLb3",
        "outputId": "b867aacc-d2f3-4d33-db25-571c9b6e3a01"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------------+--------------------+---------+\n",
            "|      username|     tweetcreatedts|              tweets|sentiment|\n",
            "+--------------+-------------------+--------------------+---------+\n",
            "|   syahpewaris|2022-05-26 23:59:33|berikut merupakan...|   netral|\n",
            "|  RiyaniEmilia|2022-05-26 23:59:31|ri di masa endemi...|   netral|\n",
            "|     JaPenWPKL|2022-05-26 23:59:10|fokus penyampaian...|   netral|\n",
            "|        DokFun|2022-05-26 23:58:48|penanganan pandem...|   netral|\n",
            "|musketeers0852|2022-05-26 23:58:39|wo tou phely b kh...|   netral|\n",
            "+--------------+-------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-HcG6fbqO8l",
        "outputId": "cb88b34b-9d1a-4430-bd44-3805f71fbdf0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1101"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split Train Test"
      ],
      "metadata": {
        "id": "IgVW4YBStJmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6-MZb1muDfE",
        "outputId": "e32de748-6620-4737-9200-4010b1ba1921"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, username: string, tweetcreatedts: string, tweets: string, sentiment: string]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_set, val_set, test_set) = df.randomSplit([0.80, 0.10, 0.10], seed = 1103)"
      ],
      "metadata": {
        "id": "XI6Yrxm-qZEd"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HashingTF + IDF + Logistic Regression"
      ],
      "metadata": {
        "id": "KYEAOHlLqjSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"tweets\", outputCol=\"words\")\n",
        "hashtf = HashingTF(numFeatures=262144, inputCol=\"words\", outputCol='tf')\n",
        "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
        "label_stringIdx = StringIndexer(inputCol = \"sentiment\", outputCol = \"label\")\n",
        "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])\n",
        "\n",
        "pipelineFit = pipeline.fit(train_set)\n",
        "train_df = pipelineFit.transform(train_set)\n",
        "val_df = pipelineFit.transform(val_set)\n",
        "train_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62YThi7jqmjo",
        "outputId": "5aa0bbef-fc4f-4804-feee-47974fbcd660"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-------------------+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
            "|       username|     tweetcreatedts|              tweets|sentiment|               words|                  tf|            features|label|\n",
            "+---------------+-------------------+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
            "|  01Karanganyar|2022-05-26 23:14:40|serma rudi anggot...|   netral|[serma, rudi, ang...|(262144,[11395,17...|(262144,[11395,17...|  0.0|\n",
            "|        02Jepon|2022-05-26 15:39:50|babinsa desa gene...|   netral|[babinsa, desa, g...|(262144,[11395,34...|(262144,[11395,34...|  0.0|\n",
            "|        02Jepon|2022-05-26 15:43:42|edukasi protkes c...|   netral|[edukasi, protkes...|(262144,[11395,13...|(262144,[11395,13...|  0.0|\n",
            "|   0723JH0722NA|2022-05-26 16:35:18|tapi udah lama ju...|   netral|[tapi, udah, lama...|(262144,[703,1139...|(262144,[703,1139...|  0.0|\n",
            "|21BeritaTerkini|2022-05-26 18:13:36|sukses vaksinasi ...|   netral|[sukses, vaksinas...|(262144,[251,1139...|(262144,[251,1139...|  0.0|\n",
            "+---------------+-------------------+--------------------+---------+--------------------+--------------------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(maxIter=100)\n",
        "lrModel = lr.fit(train_df)\n",
        "predictions = lrModel.transform(val_df)\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator()\n",
        "evaluator.evaluate(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MG1Eoy8CNNR",
        "outputId": "9a50f988-771a-4cef-97cd-1f43c380c9ce"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8253176864287975"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"tweets\", outputCol=\"words\")\n",
        "cv = CountVectorizer(vocabSize=262144, inputCol=\"words\", outputCol='cv')\n",
        "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
        "label_stringIdx = StringIndexer(inputCol = \"sentiment\", outputCol = \"label\")\n",
        "lr = LogisticRegression(maxIter=100)\n",
        "pipeline = Pipeline(stages=[tokenizer, cv, idf, label_stringIdx, lr])\n",
        "\n",
        "pipelineFit = pipeline.fit(train_set)\n",
        "predictions = pipelineFit.transform(val_set)\n",
        "Taccuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(val_set.count())\n",
        "Troc_auc = evaluator.evaluate(predictions)\n",
        "\n",
        "print (\"Accuracy Score: {0:.4f}\".format(Taccuracy))\n",
        "print (\"ROC-AUC: {0:.4f}\".format(Troc_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vdvb_yq7ZDK",
        "outputId": "4c2063c2-d2e4-42ef-e685-455573b8835f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.8148\n",
            "ROC-AUC: 0.8255\n",
            "CPU times: user 111 ms, sys: 12 ms, total: 123 ms\n",
            "Wall time: 5.84 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(val_set.count())\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFDZy1o7WShx",
        "outputId": "49e40c1b-3ad8-416d-928b-dc182816100d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8148148148148148"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CountVectorizer + IDF + Logistic Regression"
      ],
      "metadata": {
        "id": "L9Vl1S1SWhnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"tweets\", outputCol=\"words\")\n",
        "cv = CountVectorizer(vocabSize=262144, inputCol=\"words\", outputCol='cv')\n",
        "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
        "label_stringIdx = StringIndexer(inputCol = \"sentiment\", outputCol = \"label\")\n",
        "lr = LogisticRegression(maxIter=100)\n",
        "pipeline = Pipeline(stages=[tokenizer, cv, idf, label_stringIdx, lr])\n",
        "\n",
        "pipelineFit = pipeline.fit(train_set)\n",
        "predictions = pipelineFit.transform(val_set)\n",
        "Caccuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(val_set.count())\n",
        "Croc_auc = evaluator.evaluate(predictions)\n",
        "\n",
        "print (\"Accuracy Score: {0:.4f}\".format(Caccuracy))\n",
        "print (\"ROC-AUC: {0:.4f}\".format(Croc_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAb9iqlNWkHM",
        "outputId": "4550c672-1662-4e9f-bedf-833e216cde00"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.8148\n",
            "ROC-AUC: 0.8255\n",
            "CPU times: user 96.3 ms, sys: 27.1 ms, total: 123 ms\n",
            "Wall time: 4.24 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#N Gram"
      ],
      "metadata": {
        "id": "sbJsZlbSW_Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import NGram, VectorAssembler\n",
        "from pyspark.ml.feature import ChiSqSelector\n",
        "\n",
        "def build_trigrams(inputCol=[\"tweets\",\"sentiment\"], n=3):\n",
        "    tokenizer = [Tokenizer(inputCol=\"tweets\", outputCol=\"words\")]\n",
        "    ngrams = [\n",
        "        NGram(n=i, inputCol=\"words\", outputCol=\"{0}_grams\".format(i))\n",
        "        for i in range(1, n + 1)\n",
        "    ]\n",
        "\n",
        "    cv = [\n",
        "        CountVectorizer(vocabSize=262144,inputCol=\"{0}_grams\".format(i),\n",
        "            outputCol=\"{0}_tf\".format(i))\n",
        "        for i in range(1, n + 1)\n",
        "    ]\n",
        "    idf = [IDF(inputCol=\"{0}_tf\".format(i), outputCol=\"{0}_tfidf\".format(i), minDocFreq=5) for i in range(1, n + 1)]\n",
        "\n",
        "    assembler = [VectorAssembler(\n",
        "        inputCols=[\"{0}_tfidf\".format(i) for i in range(1, n + 1)],\n",
        "        outputCol=\"rawFeatures\"\n",
        "    )]\n",
        "    label_stringIdx = [StringIndexer(inputCol = \"sentiment\", outputCol = \"label\")]\n",
        "    selector = [ChiSqSelector(numTopFeatures=50,featuresCol='rawFeatures', outputCol=\"features\")]\n",
        "    lr = [LogisticRegression(maxIter=100)]\n",
        "    return Pipeline(stages=tokenizer + ngrams + cv + idf+ assembler + label_stringIdx+selector+lr)"
      ],
      "metadata": {
        "id": "UJwcvzACW9fH"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "trigram_pipelineFit = build_trigrams().fit(train_set)\n",
        "predictions = trigram_pipelineFit.transform(val_set)\n",
        "Naccuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(val_set.count())\n",
        "Nroc_auc = evaluator.evaluate(predictions)\n",
        "# print accuracy, roc_auc\n",
        "print (\"Accuracy Score: {0:.4f}\".format(Naccuracy))\n",
        "print (\"ROC-AUC: {0:.4f}\".format(Nroc_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s3abJmoXRss",
        "outputId": "75712a4f-8a2e-42ee-a595-5eddfa854cce"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.8889\n",
            "ROC-AUC: 0.8700\n",
            "CPU times: user 458 ms, sys: 60.3 ms, total: 518 ms\n",
            "Wall time: 41.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#N Gram Tanpa without Chi Squared feature selection"
      ],
      "metadata": {
        "id": "eUc5PrdxpuGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_ngrams_wocs(inputCol=[\"tweets\",\"sentiment\"], n=3):\n",
        "    tokenizer = [Tokenizer(inputCol=\"tweets\", outputCol=\"words\")]\n",
        "    ngrams = [\n",
        "        NGram(n=i, inputCol=\"words\", outputCol=\"{0}_grams\".format(i))\n",
        "        for i in range(1, n + 1)\n",
        "    ]\n",
        "\n",
        "    cv = [\n",
        "        CountVectorizer(vocabSize=262144,inputCol=\"{0}_grams\".format(i),\n",
        "            outputCol=\"{0}_tf\".format(i))\n",
        "        for i in range(1, n + 1)\n",
        "    ]\n",
        "    idf = [IDF(inputCol=\"{0}_tf\".format(i), outputCol=\"{0}_tfidf\".format(i), minDocFreq=5) for i in range(1, n + 1)]\n",
        "\n",
        "    assembler = [VectorAssembler(\n",
        "        inputCols=[\"{0}_tfidf\".format(i) for i in range(1, n + 1)],\n",
        "        outputCol=\"features\"\n",
        "    )]\n",
        "    label_stringIdx = [StringIndexer(inputCol = \"sentiment\", outputCol = \"label\")]\n",
        "    lr = [LogisticRegression(maxIter=100)]\n",
        "    return Pipeline(stages=tokenizer + ngrams + cv + idf+ assembler + label_stringIdx+lr)"
      ],
      "metadata": {
        "id": "1A6ik8UHpuVO"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "trigramwocs_pipelineFit = build_ngrams_wocs().fit(train_set)\n",
        "predictions_wocs = trigramwocs_pipelineFit.transform(val_set)\n",
        "accuracy_wocs = predictions_wocs.filter(predictions_wocs.label == predictions_wocs.prediction).count() / float(val_set.count())\n",
        "roc_auc_wocs = evaluator.evaluate(predictions_wocs)\n",
        "# print accuracy, roc_auc\n",
        "print (\"Accuracy Score: {0:.4f}\".format(accuracy_wocs))\n",
        "print (\"ROC-AUC: {0:.4f}\".format(roc_auc_wocs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-ibHagTpram",
        "outputId": "ccb82eff-f3ad-412d-c2b7-0f307462d784"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.7778\n",
            "ROC-AUC: 0.8071\n",
            "CPU times: user 368 ms, sys: 57.9 ms, total: 426 ms\n",
            "Wall time: 31.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = trigramwocs_pipelineFit.transform(test_set)\n",
        "test_accuracy = test_predictions.filter(test_predictions.label == test_predictions.prediction).count() / float(test_set.count())\n",
        "test_roc_auc = evaluator.evaluate(test_predictions)\n",
        "# print accuracy, roc_auc\n",
        "print (\"Accuracy Score: {0:.4f}\".format(test_accuracy))\n",
        "print (\"ROC-AUC: {0:.4f}\".format(test_roc_auc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxGY6kv-pUMK",
        "outputId": "3f7ffb3c-e02a-4ef3-fb44-f158e4c468dc"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 0.7589\n",
            "ROC-AUC: 0.7878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download(\"/content/preprocessed_tweets.csv\")\n",
        "# files.download(\"/content/reviews.csv\")\n",
        "# files.download(\"/content/stopwords-id.txt\")"
      ],
      "metadata": {
        "id": "TAf_oaVJ2F2t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}